import { 
  Box, 
  Button,
  VStack,
  Text,
  Flex
} from "@chakra-ui/react";
import { useState, useRef, useEffect } from "react";

export default function Home() {
  const [isOpen, setIsOpen] = useState(false);
  const videoRef = useRef(null);
  const canvasRef = useRef(null);
  const mediaRecorderRef = useRef(null);
  const [recording, setRecording] = useState(false);
  const [recordedChunks, setRecordedChunks] = useState([]);
  const [cameraStream, setCameraStream] = useState(null);
  const [canvasStream, setCanvasStream] = useState(null);

  const WIDTH = 386; // Largura final desejada
  const HEIGHT = 583; // Altura final desejada (para formato Shorts)

  // Inicia c√¢mera
  const startCamera = async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({
        // Tenta pedir a propor√ß√£o vertical, mas o browser pode dar a horizontal
        video: { 
          width: { ideal: WIDTH }, 
          height: { ideal: HEIGHT },
          facingMode: "user" // Preferir c√¢mera frontal para selfies/shorts
        },
        audio: true,
      });

      setCameraStream(stream);
      if (videoRef.current) {
        videoRef.current.srcObject = stream;
      }

      const canvas = canvasRef.current;
      const ctx = canvas.getContext("2d");
      
      // O Canvas ter√° as dimens√µes finais que queremos no v√≠deo (Vertical)
      canvas.width = WIDTH;
      canvas.height = HEIGHT;
      
      // Fun√ß√£o para desenhar o frame e aplicar a rota√ß√£o
      const drawFrame = () => {
        if (!recording || !videoRef.current || videoRef.current.readyState < 3) {
            requestAnimationFrame(drawFrame);
            return;
        }

        // Detecta se o stream da c√¢mera (videoWidth) est√° em paisagem (maior que a altura)
        const videoIsLandscape = videoRef.current.videoWidth > videoRef.current.videoHeight;

        ctx.clearRect(0, 0, canvas.width, canvas.height);
        ctx.save();

        if (videoIsLandscape) {
            // Se o v√≠deo de origem est√° horizontal, rotacionamos para preencher o canvas vertical
            const rot = Math.PI / 2; // 90 graus
            
            // Move o ponto de origem para o canto superior direito do canvas
            // O valor de 'translate' precisa ser ajustado para a rota√ß√£o correta.
            ctx.translate(canvas.width, 0); 
            ctx.rotate(rot); 

            // Desenha o v√≠deo. As dimens√µes usadas s√£o as do canvas, mas 'invertidas' pelo translate/rotate.
            // Aqui, usamos as dimens√µes do CANVAS para o preenchimento:
            ctx.drawImage(videoRef.current, 0, 0, canvas.height, canvas.width);
        } else {
            // Se o v√≠deo de origem j√° est√° vertical (ou webcam), apenas desenha
            ctx.drawImage(videoRef.current, 0, 0, canvas.width, canvas.height);
        }

        ctx.restore();
        requestAnimationFrame(drawFrame);
      };
      
      // Espera o v√≠deo carregar antes de come√ßar a desenhar
      videoRef.current.onloadedmetadata = () => {
        drawFrame();
      };
      
    } catch (err) {
      console.error("Erro ao acessar a c√¢mera:", err);
      alert("N√£o foi poss√≠vel acessar a c√¢mera. Verifique as permiss√µes.");
    }
  };

  // ... (startRecording, stopRecording, saveVideo, handleClose e useEffect de cleanup permanecem iguais)
  // ... (o JSX tamb√©m permanece igual)

  // O restante do seu c√≥digo (as fun√ß√µes de grava√ß√£o e o JSX)
  // s√£o reutilizados, pois a altera√ß√£o chave est√° apenas no startCamera.
  // ... (Inclua o restante das fun√ß√µes aqui)
  
  const startRecording = () => {
    if (!canvasRef.current) return;

    // Captura o stream do canvas que j√° est√° rotacionado
    const stream = canvasRef.current.captureStream(30); // 30 FPS
    setCanvasStream(stream);

    const mediaRecorder = new MediaRecorder(stream, {
      mimeType: "video/webm; codecs=vp9",
    });
    mediaRecorderRef.current = mediaRecorder;

    const chunks = [];
    mediaRecorder.ondataavailable = (e) => {
      if (e.data.size > 0) chunks.push(e.data);
    };

    mediaRecorder.onstop = () => {
      setRecordedChunks(chunks);
    };

    mediaRecorder.start();
    setRecording(true);
  };

  const stopRecording = () => {
    mediaRecorderRef.current?.stop();
    setRecording(false);
  };

  const saveVideo = () => {
    if (recordedChunks.length === 0) return;
    const blob = new Blob(recordedChunks, { type: "video/webm" });
    const url = URL.createObjectURL(blob);

    const a = document.createElement("a");
    a.style.display = "none";
    a.href = url;
    a.download = `video_${Date.now()}.webm`;
    document.body.appendChild(a);
    a.click();
    URL.revokeObjectURL(url);
    alert("V√≠deo salvo com sucesso!");
    setRecordedChunks([]);
  };

  const handleClose = () => {
    setIsOpen(false);
    cameraStream?.getTracks().forEach((t) => t.stop());
    setRecording(false);
  };

  // Libera c√¢mera ao fechar
  useEffect(() => {
    return () => {
      cameraStream?.getTracks().forEach((t) => t.stop());
      canvasStream?.getTracks().forEach((t) => t.stop());
    };
  }, [cameraStream, canvasStream]);
  
  // Retorno JSX:
  return (
    <Box p={8} textAlign="center">
      <Button
        colorScheme="blue"
        onClick={() => {
          setIsOpen(true);
          startCamera();
        }}
      >
        Abrir C√¢mera
      </Button>

      {isOpen && (
        <Box
          position="fixed"
          top="0"
          left="0"
          right="0"
          bottom="0"
          bg="blackAlpha.800"
          display="flex"
          alignItems="center"
          justifyContent="center"
          zIndex="9999"
          onClick={handleClose}
        >
          <Box
            w={`${WIDTH}px`}
            bg="white"
            borderRadius="xl"
            overflow="hidden"
            boxShadow="2xl"
            onClick={(e) => e.stopPropagation()}
          >
            <Flex justify="space-between" align="center" p={4} borderBottom="1px" borderColor="gray.200">
              <Text fontSize="lg" fontWeight="bold">Gravar V√≠deo</Text>
              <Button size="sm" variant="ghost" onClick={handleClose}>‚úï</Button>
            </Flex>
            
            <Box p={4}>
              <VStack gap={4}>
                {/* V√≠deo da c√¢mera (preview) */}
                <Box
                  as="video"
                  ref={videoRef}
                  autoPlay
                  playsInline
                  muted
                  w="100%"
                  h="444px"
                  bg="black"
                  borderRadius="md"
                />

                {/* Canvas invis√≠vel usado para grava√ß√£o */}
                <canvas ref={canvasRef} style={{ display: "none" }} />

                {!recording ? (
                  <Button colorScheme="green" onClick={startRecording} w="full">
                    ‚ñ∂Ô∏è Iniciar Grava√ß√£o
                  </Button>
                ) : (
                  <Button colorScheme="red" onClick={stopRecording} w="full">
                    ‚èπÔ∏è Parar Grava√ß√£o
                  </Button>
                )}

                {recordedChunks.length > 0 && (
                  <Button colorScheme="blue" onClick={saveVideo} w="full">
                    üíæ Salvar V√≠deo
                  </Button>
                )}

                <Text fontSize="xs" color="gray.500">
                  Resolu√ß√£o de grava√ß√£o: {WIDTH}√ó{HEIGHT}px (Vertical For√ßado)
                </Text>
              </VStack>
            </Box>
          </Box>
        </Box>
      )}
    </Box>
  );
}