import { 
  Box, 
  Button,
  VStack,
  Text,
  Flex
} from "@chakra-ui/react";
import { useState, useRef, useEffect } from "react";

export default function Home() {
  const videoRef = useRef(null);
  const mediaRecorderRef = useRef(null);
  const cameraStreamRef = useRef(null);
  const canvasRef = useRef(null);
  const recordedChunksRef = useRef([]);

  const [isOpen, setIsOpen] = useState(false);
  const [recording, setRecording] = useState(false);
  const [recordedChunks, setRecordedChunks] = useState([]);

  const WIDTH = 386; // desktop
  const HEIGHT = 583;

  // Inicia c√¢mera
  const startCamera = async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({
        video: { facingMode: "environment" },
        audio: true,
      });

      cameraStreamRef.current = stream;

      if (videoRef.current) {
        videoRef.current.srcObject = stream;
        videoRef.current.onloadedmetadata = () => videoRef.current.play().catch(console.error);
      }
    } catch (err) {
      console.warn("Falha c√¢mera traseira, tentando frontal:", err);
      try {
        const stream = await navigator.mediaDevices.getUserMedia({
          video: { facingMode: "user" },
          audio: true,
        });

        cameraStreamRef.current = stream;

        if (videoRef.current) {
          videoRef.current.srcObject = stream;
          videoRef.current.onloadedmetadata = () => videoRef.current.play().catch(console.error);
        }
      } catch (fallbackErr) {
        console.error("N√£o foi poss√≠vel acessar a c√¢mera:", fallbackErr);
        alert("N√£o foi poss√≠vel acessar a c√¢mera. Verifique as permiss√µes.");
      }
    }
  };

  // Iniciar grava√ß√£o usando canvas
  const startRecording = () => {
    const video = videoRef.current;
    const stream = cameraStreamRef.current;
    if (!video || !stream) {
      alert("C√¢mera n√£o est√° pronta. Aguarde alguns segundos.");
      return;
    }

    const canvas = document.createElement("canvas");
    canvas.width = WIDTH;
    canvas.height = HEIGHT;
    const ctx = canvas.getContext("2d");
    canvasRef.current = canvas;

    const canvasStream = canvas.captureStream(30); // 30 fps
    stream.getAudioTracks().forEach(track => canvasStream.addTrack(track));

    const mimeType = MediaRecorder.isTypeSupported("video/webm;codecs=vp9")
      ? "video/webm;codecs=vp9"
      : MediaRecorder.isTypeSupported("video/webm;codecs=vp8")
      ? "video/webm;codecs=vp8"
      : "video/webm";

    const mediaRecorder = new MediaRecorder(canvasStream, { mimeType, videoBitsPerSecond: 2500000 });
    mediaRecorderRef.current = mediaRecorder;

    recordedChunksRef.current = []; // reset
    mediaRecorder.ondataavailable = e => {
      if (e.data.size > 0) recordedChunksRef.current.push(e.data);
    };

    mediaRecorder.onstop = () => {
      setRecordedChunks(recordedChunksRef.current); // atualiza estado para mostrar bot√£o
    };

    mediaRecorder.start(100);
    setRecording(true);

    const draw = () => {
      if (!recording) return;
      ctx.fillStyle = "black";
      ctx.fillRect(0, 0, WIDTH, HEIGHT);

      const videoRatio = video.videoWidth / video.videoHeight;
      const canvasRatio = WIDTH / HEIGHT;

      let drawWidth = WIDTH;
      let drawHeight = HEIGHT;
      let offsetX = 0;
      let offsetY = 0;

      if (videoRatio > canvasRatio) {
        drawWidth = video.videoHeight * canvasRatio;
        offsetX = (video.videoWidth - drawWidth) / 2;
      } else {
        drawHeight = video.videoWidth / canvasRatio;
        offsetY = (video.videoHeight - drawHeight) / 2;
      }

      ctx.drawImage(video, offsetX, offsetY, drawWidth, drawHeight, 0, 0, WIDTH, HEIGHT);
      requestAnimationFrame(draw);
    };
    draw();
  };

  // Parar grava√ß√£o
  const stopRecording = () => {
    if (mediaRecorderRef.current && recording) {
      mediaRecorderRef.current.stop();
      setRecording(false);
    }
  };

  // Salvar v√≠deo
  const saveVideo = () => {
    if (recordedChunks.length === 0) {
      alert("Nenhum v√≠deo gravado!");
      return;
    }

    const blob = new Blob(recordedChunks, { type: "video/webm" });
    const url = URL.createObjectURL(blob);

    const a = document.createElement("a");
    a.style.display = "none";
    a.href = url;
    a.download = `video_${Date.now()}.webm`;
    document.body.appendChild(a);
    a.click();

    setTimeout(() => {
      document.body.removeChild(a);
      URL.revokeObjectURL(url);
    }, 100);

    alert("V√≠deo salvo! Verifique a pasta de Downloads.");
    setRecordedChunks([]);
  };

  // Fechar modal e liberar c√¢mera
  const handleClose = () => {
    if (recording) stopRecording();
    setIsOpen(false);
    cameraStreamRef.current?.getTracks().forEach(track => track.stop());
    cameraStreamRef.current = null;
    setRecordedChunks([]);
  };

  useEffect(() => {
    return () => {
      cameraStreamRef.current?.getTracks().forEach(track => track.stop());
    };
  }, []);

  return (
    <Box p={8} textAlign="center">
      <Button
        colorScheme="blue"
        size="lg"
        onClick={() => {
          setIsOpen(true);
          startCamera();
        }}
      >
        üìπ Abrir C√¢mera
      </Button>

      {isOpen && (
        <Box
          position="fixed"
          top="0"
          left="0"
          right="0"
          bottom="0"
          bg="blackAlpha.800"
          display="flex"
          alignItems="center"
          justifyContent="center"
          zIndex="9999"
          onClick={handleClose}
        >
          <Box
            maxW="90vw"
            maxH="90vh"
            bg="white"
            borderRadius="xl"
            overflow="hidden"
            boxShadow="2xl"
            onClick={(e) => e.stopPropagation()}
          >
            <Flex justify="space-between" align="center" p={4} borderBottom="1px" borderColor="gray.200">
              <Text fontSize="lg" fontWeight="bold">
                {recording ? "üî¥ Gravando..." : "Gravar V√≠deo"}
              </Text>
              <Button size="sm" variant="ghost" onClick={handleClose}>‚úï</Button>
            </Flex>
            
            <Box p={4}>
              <VStack gap={4}>
                <Box
                  as="video"
                  ref={videoRef}
                  autoPlay
                  playsInline
                  muted
                  maxW="100%"
                  maxH="60vh"
                  bg="black"
                  borderRadius="md"
                />

                {!recording ? (
                  <Button colorScheme="green" onClick={startRecording} w="full" size="lg">
                    ‚ñ∂Ô∏è Iniciar Grava√ß√£o
                  </Button>
                ) : (
                  <Button colorScheme="red" onClick={stopRecording} w="full" size="lg">
                    ‚èπÔ∏è Parar Grava√ß√£o
                  </Button>
                )}

                {recordedChunks.length > 0 && (
                  <Button colorScheme="blue" onClick={saveVideo} w="full" size="lg">
                    üíæ Salvar V√≠deo
                  </Button>
                )}

                <Text fontSize="xs" color="gray.500">
                  Resolu√ß√£o for√ßada: 386x583 (9:16)
                </Text>
              </VStack>
            </Box>
          </Box>
        </Box>
      )}
    </Box>
  );
}
