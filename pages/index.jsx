import { 
  Box, 
  Button,
  VStack,
  Text,
  Flex
} from "@chakra-ui/react";
import { useState, useRef, useEffect } from "react";

export default function Home() {
  const [isOpen, setIsOpen] = useState(false);
  const videoRef = useRef(null);
  const canvasRef = useRef(null);
  const mediaRecorderRef = useRef(null);
  const [recording, setRecording] = useState(false);
  const [recordedChunks, setRecordedChunks] = useState([]);
  const [cameraStream, setCameraStream] = useState(null);
  const [canvasStream, setCanvasStream] = useState(null);
  const animationFrameRef = useRef(null);

  const WIDTH = 386;
  const HEIGHT = 583;

  // Inicia c√¢mera traseira
  const startCamera = async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({
        video: { 
          width: { ideal: WIDTH }, 
          height: { ideal: HEIGHT },
          facingMode: { exact: "environment" } // For√ßa c√¢mera traseira
        },
        audio: true,
      });

      setCameraStream(stream);
      if (videoRef.current) {
        videoRef.current.srcObject = stream;
      }

      // Configura o canvas para capturar o v√≠deo
      const canvas = canvasRef.current;
      const ctx = canvas.getContext("2d");
      canvas.width = WIDTH;
      canvas.height = HEIGHT;

      // Renderiza os frames da c√¢mera no canvas SEMPRE (n√£o s√≥ quando recording)
      const drawFrame = () => {
        if (videoRef.current && videoRef.current.readyState === videoRef.current.HAVE_ENOUGH_DATA) {
          ctx.drawImage(videoRef.current, 0, 0, WIDTH, HEIGHT);
        }
        animationFrameRef.current = requestAnimationFrame(drawFrame);
      };
      drawFrame();
    } catch (err) {
      console.error("Erro ao acessar a c√¢mera:", err);
      // Tenta c√¢mera frontal como fallback
      try {
        const stream = await navigator.mediaDevices.getUserMedia({
          video: { 
            width: { ideal: WIDTH }, 
            height: { ideal: HEIGHT },
            facingMode: "user"
          },
          audio: true,
        });
        
        setCameraStream(stream);
        if (videoRef.current) {
          videoRef.current.srcObject = stream;
        }

        const canvas = canvasRef.current;
        const ctx = canvas.getContext("2d");
        canvas.width = WIDTH;
        canvas.height = HEIGHT;

        const drawFrame = () => {
          if (videoRef.current && videoRef.current.readyState === videoRef.current.HAVE_ENOUGH_DATA) {
            ctx.drawImage(videoRef.current, 0, 0, WIDTH, HEIGHT);
          }
          animationFrameRef.current = requestAnimationFrame(drawFrame);
        };
        drawFrame();
      } catch (fallbackErr) {
        console.error("Erro ao acessar c√¢mera frontal:", fallbackErr);
        alert("N√£o foi poss√≠vel acessar a c√¢mera. Verifique as permiss√µes.");
      }
    }
  };

  const startRecording = () => {
    if (!canvasRef.current) return;

    const stream = canvasRef.current.captureStream(30); // 30 FPS
    
    // Adiciona o √°udio da c√¢mera ao stream do canvas
    if (cameraStream) {
      const audioTracks = cameraStream.getAudioTracks();
      audioTracks.forEach(track => stream.addTrack(track));
    }
    
    setCanvasStream(stream);

    const mediaRecorder = new MediaRecorder(stream, {
      mimeType: "video/webm; codecs=vp9",
    });
    mediaRecorderRef.current = mediaRecorder;

    const chunks = [];
    mediaRecorder.ondataavailable = (e) => {
      if (e.data.size > 0) chunks.push(e.data);
    };

    mediaRecorder.onstop = () => {
      setRecordedChunks(chunks);
    };

    mediaRecorder.start();
    setRecording(true);
  };

  const stopRecording = () => {
    mediaRecorderRef.current?.stop();
    setRecording(false);
  };

  const saveVideo = () => {
    if (recordedChunks.length === 0) return;
    const blob = new Blob(recordedChunks, { type: "video/webm" });
    const url = URL.createObjectURL(blob);

    const a = document.createElement("a");
    a.style.display = "none";
    a.href = url;
    a.download = `video_${Date.now()}.webm`;
    document.body.appendChild(a);
    a.click();
    URL.revokeObjectURL(url);
    alert("V√≠deo salvo com sucesso!");
    setRecordedChunks([]);
  };

  const handleClose = () => {
    setIsOpen(false);
    if (animationFrameRef.current) {
      cancelAnimationFrame(animationFrameRef.current);
    }
    cameraStream?.getTracks().forEach((t) => t.stop());
    canvasStream?.getTracks().forEach((t) => t.stop());
    setRecording(false);
    setRecordedChunks([]);
  };

  // Libera recursos ao fechar
  useEffect(() => {
    return () => {
      if (animationFrameRef.current) {
        cancelAnimationFrame(animationFrameRef.current);
      }
      cameraStream?.getTracks().forEach((t) => t.stop());
      canvasStream?.getTracks().forEach((t) => t.stop());
    };
  }, [cameraStream, canvasStream]);

  return (
    <Box p={8} textAlign="center">
      <Button
        colorScheme="blue"
        onClick={() => {
          setIsOpen(true);
          startCamera();
        }}
      >
        Abrir C√¢mera
      </Button>

      {isOpen && (
        <Box
          position="fixed"
          top="0"
          left="0"
          right="0"
          bottom="0"
          bg="blackAlpha.800"
          display="flex"
          alignItems="center"
          justifyContent="center"
          zIndex="9999"
          onClick={handleClose}
        >
          <Box
            w={`${WIDTH}px`}
            bg="white"
            borderRadius="xl"
            overflow="hidden"
            boxShadow="2xl"
            onClick={(e) => e.stopPropagation()}
          >
            <Flex justify="space-between" align="center" p={4} borderBottom="1px" borderColor="gray.200">
              <Text fontSize="lg" fontWeight="bold">Gravar V√≠deo</Text>
              <Button size="sm" variant="ghost" onClick={handleClose}>‚úï</Button>
            </Flex>
            
            <Box p={4}>
              <VStack gap={4}>
                {/* V√≠deo da c√¢mera */}
                <Box
                  as="video"
                  ref={videoRef}
                  autoPlay
                  playsInline
                  muted
                  w="100%"
                  h="444px"
                  bg="black"
                  borderRadius="md"
                  style={{ objectFit: 'cover' }}
                />

                {/* Canvas invis√≠vel usado para grava√ß√£o */}
                <canvas ref={canvasRef} style={{ display: "none" }} />

                {!recording ? (
                  <Button colorScheme="green" onClick={startRecording} w="full">
                    ‚ñ∂Ô∏è Iniciar Grava√ß√£o
                  </Button>
                ) : (
                  <Button colorScheme="red" onClick={stopRecording} w="full">
                    ‚èπÔ∏è Parar Grava√ß√£o
                  </Button>
                )}

                {recordedChunks.length > 0 && (
                  <Button colorScheme="blue" onClick={saveVideo} w="full">
                    üíæ Salvar V√≠deo
                  </Button>
                )}

                <Text fontSize="xs" color="gray.500">
                  Resolu√ß√£o: {WIDTH}√ó{HEIGHT}px | C√¢mera traseira
                </Text>
              </VStack>
            </Box>
          </Box>
        </Box>
      )}
    </Box>
  );
}